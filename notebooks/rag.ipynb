{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://python.langchain.com/v0.2/docs/tutorials/rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\anaconda\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\anaconda\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\anaconda\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\anaconda\\lib\\site-packages (from langchain) (0.3.15)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\anaconda\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\anaconda\\lib\\site-packages (from langchain) (0.1.134)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\anaconda\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\anaconda\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\anaconda\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\anaconda\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\anaconda\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\anaconda\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\anaconda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\anaconda\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tenacity==8.5.0 in c:\\anaconda\\lib\\site-packages (8.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install tenacity==8.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet --upgrade langchain langchain-community langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure to replace the api key with your own! i don't wanna be charged for too many calls LMAOO\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override = True)\n",
    "\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again, replace with your own open ai api key\n",
    "#not sure how fast we're gonna use our free calls but we should prob create a local free rag application with ollama if goldhirsh doesn't give us funding soon\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# file_path='./idea-2024-new.json'\n",
    "# data = json.loads(Path(file_path).read_text(encoding='utf-8'))\n",
    "# loader = JSONLoader(\n",
    "#          file_path=file_path,\n",
    "#          jq_schema=\".[].summary\",\n",
    "#          text_content=True)\n",
    "\n",
    "file_path='./all_data2.json'\n",
    "data = json.loads(Path(file_path).read_text(encoding='utf-8'))\n",
    "loader = JSONLoader(\n",
    "         file_path=file_path,\n",
    "         jq_schema=\".[].OrganizationText\",\n",
    "         text_content=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7616"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m splitter \u001b[38;5;241m=\u001b[39m RecursiveJsonSplitter(max_chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Recursively split json data - If you need to access/manipulate the smaller json chunks\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m json_chunks \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit_json(json_data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(json_chunks)\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\langchain_text_splitters\\json.py:91\u001b[0m, in \u001b[0;36mRecursiveJsonSplitter.split_json\u001b[1;34m(self, json_data, convert_lists)\u001b[0m\n\u001b[0;32m     89\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_json_split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list_to_dict_preprocessing(json_data))\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_json_split(json_data)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Remove the last chunk if it's empty\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunks[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\langchain_text_splitters\\json.py:78\u001b[0m, in \u001b[0;36mRecursiveJsonSplitter._json_split\u001b[1;34m(self, data, current_path, chunks)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_json_split(value, new_path, chunks)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# handle single item\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_nested_dict(chunks[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], current_path, data)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n",
      "File \u001b[1;32mC:\\anaconda\\Lib\\site-packages\\langchain_text_splitters\\json.py:32\u001b[0m, in \u001b[0;36mRecursiveJsonSplitter._set_nested_dict\u001b[1;34m(d, path, value)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m path[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     31\u001b[0m     d \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39msetdefault(key, {})\n\u001b[1;32m---> 32\u001b[0m d[path[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from uuid import uuid4\n",
    "import math\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Initialize an empty Chroma vector store with a persistence directory\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"my_collection\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma_langchain_db\"  # Specify a directory to persist data\n",
    ")\n",
    "\n",
    "# Split `all_splits` into smaller batches\n",
    "batch_size = 500  # Adjust this based on memory and performance needs\n",
    "num_batches = math.ceil(len(all_splits) / batch_size)\n",
    "\n",
    "for i in range(num_batches):\n",
    "    # Extract the current batch\n",
    "    batch = all_splits[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "    # Generate unique IDs for the documents in the batch\n",
    "    batch_ids = [str(uuid4()) for _ in range(len(batch))]\n",
    "\n",
    "    # Add the batch of documents directly to the vector store\n",
    "    vectorstore.add_documents(documents=batch, ids=batch_ids)\n",
    "\n",
    "print(\"All documents have been embedded and added to the vector store.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can help organizations like those focused on community college access for 6-12th graders, re-establishing support services in Los Angeles County, and community-building events and projects through Big Sunday. These organizations work towards education, empowerment, and community development in underserved populations in Los Angeles.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "#### RETRIEVAL and GENERATION ####\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain.invoke(\"What are organizations I can help based on my interests?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vision Possible and Food on Foot are two organizations that work to help the homeless in Los Angeles. Vision Possible aims to conduct a vision to help the homeless regain their lives and be productive citizens, while Food on Foot works to alleviate homelessness by providing meals, supplies, and assistance in securing jobs and permanent housing.\n",
      "\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"Which organizations help the homeless?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "print()\n",
    "response2 = rag_chain.invoke({\"input\": \"What is food on foot's IRS standing?\"})\n",
    "print(response2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Homelessness is not an individual issue. It is a community issue. Our organization, Vision Possible, aims to conduct a  vision to help the homeless regain their lives and be productive citizens like you and me.' metadata={'seq_num': 266, 'source': 'C:\\\\Users\\\\Vivien Chen\\\\Desktop\\\\LA2050chatbot\\\\notebooks\\\\idea-2024-new.json', 'start_index': 0}\n",
      "\n",
      "page_content='This grant will go towards three separate projects/programs that have the same targeted audience â€“ the homeless. The first project is to help reunify homeless people with their families/friends (if they so choose) through the creation of a homeless directory that would be available for the public to use, secondly, raise awareness about the daily struggles the homeless face in LA, and lastly, to promote homeless organizations with free ads.' metadata={'seq_num': 709, 'source': 'C:\\\\Users\\\\Vivien Chen\\\\Desktop\\\\LA2050chatbot\\\\notebooks\\\\idea-2024-new.json', 'start_index': 0}\n",
      "\n",
      "page_content='Food on Foot works to alleviate homelessness in Los Angeles by fulfilling two crucial needs: our weekly Sunday Serving event provides our hungry and unhoused neighbors with healthy meals and supplies, while our Jobs & Housing Program assists people in securing jobs, permanent housing, and independence. We seek to scale our services through an innovative and successful new volunteer initiative called FRIENDS. To meet the need we are requesting the necessary funds to hire a Mental Health Leader to provide guidance, leadership, and direct service.' metadata={'seq_num': 221, 'source': 'C:\\\\Users\\\\Vivien Chen\\\\Desktop\\\\LA2050chatbot\\\\notebooks\\\\idea-2024-new.json', 'start_index': 0}\n",
      "\n",
      "page_content='Families with young children who are homeless or housing insecure are an all-too frequently overlooked group impacted by Los Angeles' greatest community crisis. We are bringing together, for the first time, homelessness and early childhood nonprofits to identify and act on concrete solutions to their challenges and to raise their issues to elected leaders, influencers and the public.' metadata={'seq_num': 54, 'source': 'C:\\\\Users\\\\Vivien Chen\\\\Desktop\\\\LA2050chatbot\\\\notebooks\\\\idea-2024-new.json', 'start_index': 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document in response[\"context\"]:\n",
    "    print(document)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: add message history\n",
    "#https://python.langchain.com/docs/how_to/message_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: local rag application (so we can do more in depth testing without making too many open ai api calls) - using ollama?\n",
    "#https://python.langchain.com/v0.2/docs/tutorials/local_rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can consider supporting organizations like The Gentle Barn, Fostering UNITY, or programs like the \"Healing Hooves\" that provide mental health support to foster youth through Equine Assisted Therapy. These initiatives focus on empowering youth through interactions with rescued animals and promoting healing and growth through animal-assisted activities.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load or initialize message history\n",
    "message_history = []\n",
    "if os.path.exists(\"message_history.json\"):\n",
    "    with open(\"message_history.json\", \"r\") as f:\n",
    "        try:\n",
    "            message_history = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            message_history = []\n",
    "\n",
    "# Function to update message history with serialization\n",
    "def update_message_history(user_query, bot_response, retrieved_context=None):\n",
    "    if retrieved_context and isinstance(retrieved_context, list):\n",
    "        serialized_context = [\n",
    "            {\"page_content\": doc.page_content, \"metadata\": doc.metadata} if hasattr(doc, \"page_content\") else str(doc)\n",
    "            for doc in retrieved_context\n",
    "        ]\n",
    "    else:\n",
    "        serialized_context = retrieved_context\n",
    "\n",
    "    if bot_response and bot_response.lower() != \"i don't know\":\n",
    "        entry = {\n",
    "            \"query\": user_query,\n",
    "            \"response\": bot_response,\n",
    "            \"retrieved_context\": serialized_context,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        message_history.append(entry)\n",
    "\n",
    "# Function to format the prompt with recent message history for context\n",
    "def format_prompt_with_history(history, current_query, n=3):\n",
    "    context = \"\\n\".join(\n",
    "        [f\"User: {entry['query']}\\nBot: {entry['response']}\" for entry in history[-n:]]\n",
    "    )\n",
    "    return f\"{context}\\nUser: {current_query}\\nBot:\"\n",
    "\n",
    "user_query = \"What are organizations I can help based on my interests?\"\n",
    "\n",
    "# Test query with history\n",
    "prompt_with_history = format_prompt_with_history(message_history, user_query)\n",
    "response_with_history = rag_chain.invoke({\"input\": prompt_with_history})\n",
    "bot_response_with_history = response_with_history.get(\"answer\", \"No response found\")\n",
    "print(bot_response_with_history)\n",
    "\n",
    "# Update message history and save if the response is meaningful\n",
    "update_message_history(user_query, bot_response_with_history, response_with_history.get(\"context\"))\n",
    "with open(\"message_history.json\", \"w\") as f:\n",
    "    json.dump(message_history, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
